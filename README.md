# Large-Language-Models-as-Information-Curator

This repository contains the research and analysis conducted to audit the performance of nine large language models (LLMs) from OpenAI, Google, and Meta in evaluating the credibility and political bias of the top 20 most popular Bangladeshi news outlets.

## Research Overview
Search engines and AI chatbots are increasingly leveraging LLMs to provide direct answers and retrieve updated information. As key information curators for billions of users, it is critical to assess their ability to evaluate the accuracy and reliability of sources.

## Key Findings:
LLM Behavior: Larger models often refuse to rate sources due to insufficient information.
Smaller models are prone to hallucinating responses.

Consistency and Alignment: LLMs show strong internal consistency (average correlation coefficient ùúå = 0.72).
Alignment with human expert evaluations is moderate (average ùúå = 0.45).
Political Bias: Default LLM configurations favor sources affiliated with The Bangladesh Awami League.
Assigning partisan identities amplifies politically congruent biases.

Dataset Contribution: A dataset of expert opinions on the credibility and political bias of Bangladeshi news outlets was created for this study.

Implications:These findings underscore the need to address political bias and improve credibility evaluations as LLMs play a growing role in curating news and political information worldwide.

## Repository Contents
Dataset: Expert opinions on Bangladeshi news outlets.
Scripts: Code for analyzing LLM performance in credibility and bias assessment.
Results: Tables and figures summarizing LLM performance and biases.

## Collaborators
Tabia Tanzin Prama‚àó
Email: tabiatanzin1234@gmail.com

Md. Saiful Islam
Email: saiful.islam@newcastle.edu.au


Md. Musfique Anwar
Email: manwar@juniv.edu
